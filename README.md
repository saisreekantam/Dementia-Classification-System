# CogniCare - Dementia Detection & Cognitive Assessment Platform

## ğŸ¥ Live Demo & Media

### ğŸ“± Application Screenshots
**[View Webapp Screenshots & Interface Images â†’](DRIVE_LINK_PLACEHOLDER)**  
*Complete visual walkthrough of the application interface, assessment flows, and dashboard features*

### ğŸ¬ Video Demonstration  
**[Watch Full Demo Video â†’](YOUTUBE_LINK_PLACEHOLDER)**  
*Comprehensive demonstration of all assessment modules and platform capabilities*

---

## ğŸ§  Project Overview

CogniCare is a comprehensive web-based platform for early detection of cognitive impairment and dementia using scientifically-validated neuropsychological assessments combined with advanced machine learning analysis. The platform provides healthcare professionals with tools to conduct standardized cognitive assessments and analyze language patterns for potential indicators of Alzheimer's disease and related dementias.

## âœ¨ Key Features

### ğŸ”¬ Comprehensive Assessment Battery
- **Memory Recall Test** - Evaluates short-term and long-term memory with word list exercises
- **Verbal Fluency Assessment** - Tests language abilities and cognitive flexibility 
- **Trail Making Test** - Assesses visual attention and executive function
- **Stroop Color Test** - Measures cognitive inhibition and processing speed
- **Cookie Theft Picture Description** - Analyzes language and scene description capabilities

### ğŸ¤– AI-Powered Analysis
- Advanced NLP models for analyzing speech patterns and linguistic features
- Machine learning algorithms trained to detect early signs of cognitive impairment
- Confidence scoring and risk level assessment
- Clinical interpretation and recommendations

### ğŸ“Š Clinical Dashboard
- Patient management and assessment tracking
- Progress monitoring over time
- Comprehensive reporting and data visualization
- Secure authentication and authorization

### ğŸ¯ CogniCare Cognitive Composite Score (CCS)
- Scientifically-validated composite scoring system
- Population norm-based Z-score calculations
- Risk stratification (healthy, mild concern, strong indication)
- Detailed domain-specific analysis

## ğŸ—ï¸ Project Structure

```
cognicare/
â”œâ”€â”€ frontend/                    # React TypeScript Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/            # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ AssessmentCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CogniCareResults.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MayaAvatar.tsx  # AI assistant avatar
â”‚   â”‚   â”‚   â””â”€â”€ ProtectedRoute.tsx
â”‚   â”‚   â”œâ”€â”€ pages/             # Main application pages
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx   # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.tsx      # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ Register.tsx   # User registration
â”‚   â”‚   â”‚   â”œâ”€â”€ ComprehensiveAssessment.tsx  # Full battery
â”‚   â”‚   â”‚   â”œâ”€â”€ MemoryAssessment.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VerbalFluencyAssessment.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TrailMakingAssessment.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StroopColorAssessment.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CookieTheftAssessment.tsx
â”‚   â”‚   â”‚   â””â”€â”€ NotFound.tsx
â”‚   â”‚   â”œâ”€â”€ contexts/          # React contexts
â”‚   â”‚   â”‚   â””â”€â”€ AuthContext.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/             # Custom React hooks
â”‚   â”‚   â””â”€â”€ lib/               # Utility functions
â”‚   â”œâ”€â”€ public/                # Static assets
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â””â”€â”€ components.json        # shadcn/ui configuration
â”‚
â”œâ”€â”€ backend/                    # FastAPI Python Backend
â”‚   â”œâ”€â”€ main.py                # FastAPI application entry point
â”‚   â”œâ”€â”€ database.py            # Database configuration and connection
â”‚   â”œâ”€â”€ models.py              # SQLAlchemy database models
â”‚   â”œâ”€â”€ schemas.py             # Pydantic request/response schemas
â”‚   â”œâ”€â”€ auth.py                # Authentication and authorization
â”‚   â”œâ”€â”€ nlp_service.py         # ML/NLP analysis service
â”‚   â”œâ”€â”€ init_db.py             # Database initialization script
â”‚   â”œâ”€â”€ start.py               # Development server startup script
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ .env.template          # Environment variables template
â”‚   â””â”€â”€ model_files/           # ML model artifacts (*.pkl files)
â”‚       â”œâ”€â”€ model_control.pkl  # Control group classifier
â”‚       â”œâ”€â”€ model_alz.pkl      # Alzheimer's classifier
â”‚       â””â”€â”€ vectorizer.pkl     # Text vectorizer
â”‚
â””â”€â”€ README.md                  # This file
```

## ğŸ› ï¸ Technology Stack

### Frontend Technologies
- **React 18.3.1** - Modern UI framework with hooks and context
- **TypeScript 5.8.3** - Type-safe JavaScript development
- **Vite 5.4.19** - Fast build tool and development server
- **Tailwind CSS 3.4.17** - Utility-first CSS framework
- **shadcn/ui** - High-quality, accessible component library built on Radix UI
- **React Router 6.30.1** - Client-side routing and navigation
- **React Query (TanStack)** - Server state management and caching
- **React Hook Form** - Performant forms with minimal re-renders
- **Axios** - HTTP client for API communication
- **Lucide React** - Beautiful, customizable SVG icons
- **Recharts** - Composable charting library for data visualization

### Backend Technologies
- **FastAPI** - Modern, fast web framework for building APIs
- **Python 3.8+** - Programming language for backend development
- **SQLAlchemy** - SQL toolkit and Object-Relational Mapping (ORM)
- **SQLite** - Lightweight, file-based database (configurable to PostgreSQL)
- **Pydantic** - Data validation using Python type annotations
- **JWT (PyJWT)** - JSON Web Token authentication
- **Passlib & bcrypt** - Password hashing and verification
- **Uvicorn** - ASGI server for running FastAPI applications

### Machine Learning & NLP
- **scikit-learn** - Machine learning algorithms and data preprocessing
- **spaCy** - Advanced NLP library for text processing
- **NLTK** - Natural Language Toolkit for linguistic analysis
- **pickle/dill** - Model serialization and deserialization
- **regex** - Advanced pattern matching for text processing

### Development Tools
- **ESLint** - JavaScript/TypeScript linting
- **Prettier** - Code formatting
- **Git** - Version control system

## ğŸš€ Getting Started

### Prerequisites
- **Node.js 18+** and npm (for frontend)
- **Python 3.8+** and pip (for backend)
- **Git** (for version control)

### Backend Setup

1. **Navigate to backend directory**
   ```bash
   cd backend
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download spaCy language model**
   ```bash
   python -m spacy download en_core_web_sm
   ```

4. **Set up environment variables**
   ```bash
   cp .env.template .env
   # Edit .env file with your configuration
   ```

5. **Add ML model files**
   Place the required machine learning model files in the backend directory:
   - `model_control.pkl` - Control group classifier
   - `model_alz.pkl` - Alzheimer's detection model  
   - `vectorizer.pkl` - Text feature vectorizer

6. **Initialize database**
   ```bash
   python init_db.py demo
   ```

7. **Start development server**
   ```bash
   python start.py
   ```
   *Backend will be available at http://localhost:8000*

### Frontend Setup

1. **Navigate to frontend directory**
   ```bash
   cd frontend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start development server**
   ```bash
   npm run dev
   ```
   *Frontend will be available at http://localhost:8080*

### Quick Setup Script

For automated backend setup:
```bash
cd backend
python start.py setup  # Complete environment setup
python start.py         # Start development server
python start.py check   # Verify system requirements
```

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Database Configuration
DATABASE_URL=sqlite:///./dementia_detection.db

# JWT Configuration  
SECRET_KEY=your-secret-key-change-this-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:8080
```

### Database Configuration

The application uses SQLite by default but can be configured for PostgreSQL:

```python
# For PostgreSQL
DATABASE_URL=postgresql://username:password@localhost/dbname
```

## ğŸ“Š Assessment Details

### 1. Memory Recall Test (10-15 min)
- **Purpose**: Evaluates immediate and delayed memory recall
- **Method**: Word list learning with immediate and delayed recall tasks
- **Scoring**: Number of words correctly recalled
- **Population Norm**: Mean 12.5 Â± 2.8 words

### 2. Verbal Fluency Assessment (5 min)
- **Purpose**: Tests semantic memory and executive function
- **Method**: Generate words from specific categories (e.g., animals)
- **Scoring**: Number of valid, unique words produced
- **Population Norm**: Mean 18.2 Â± 4.3 words

### 3. Trail Making Test (8-12 min)
- **Purpose**: Assesses visual attention and task switching
- **Method**: Connect numbered and lettered circles in sequence
- **Scoring**: Time to completion for Part B
- **Population Norm**: Mean 75.0 Â± 25.0 seconds

### 4. Stroop Color Test (8-10 min)
- **Purpose**: Measures cognitive inhibition and processing speed
- **Method**: Name colors while ignoring word content
- **Scoring**: Interference effect calculation
- **Population Norm**: Mean 650 Â± 180 ms interference

### 5. Cookie Theft Picture Description (5-8 min)
- **Purpose**: Evaluates language production and cognitive processing
- **Method**: Describe complex picture scene
- **Scoring**: Information units and linguistic analysis
- **Population Norm**: Mean 14.5 Â± 3.2 information units

## ğŸ”¬ Machine Learning Pipeline

### NLP Analysis Process
1. **Text Preprocessing**
   - Tokenization and normalization
   - POS tagging and grammatical analysis
   - Feature extraction (linguistic patterns, word frequency)

2. **Model Prediction**
   - Dual-model approach (Control vs. Alzheimer's)
   - Confidence scoring and risk assessment
   - Clinical interpretation generation

3. **Feature Analysis**
   - Word count and sentence structure
   - Lexical diversity and semantic content
   - Grammatical complexity metrics

## ğŸ”’ Security Features

- **JWT-based authentication** with secure token handling
- **Password hashing** using bcrypt with salt
- **Role-based access control** (Admin, Doctor, Researcher)
- **CORS protection** for API endpoints
- **Input validation** using Pydantic schemas
- **SQL injection protection** via SQLAlchemy ORM

## ğŸ“ˆ API Endpoints

### Authentication
- `POST /auth/register` - User registration
- `POST /auth/token` - Login and token generation
- `GET /auth/me` - Get current user profile

### Patient Management  
- `POST /patients` - Create new patient
- `GET /patients` - List patients for current doctor
- `GET /patients/{id}` - Get specific patient details

### Assessments
- `POST /assessments` - Create new assessment
- `GET /assessments/{id}` - Get assessment details
- `PUT /assessments/{id}` - Update assessment results

### NLP Analysis
- `POST /nlp/analyze` - Analyze text for cognitive indicators
- `GET /nlp/analysis/{id}` - Get analysis results
- `GET /patients/{id}/progress` - Get patient progress over time

### System
- `GET /` - API health check
- `GET /health` - Detailed system status
- `GET /docs` - Interactive API documentation (Swagger UI)

## ğŸ§ª Development Commands

### Backend Commands
```bash
# Setup and start
python start.py setup      # Complete environment setup
python start.py           # Start development server  
python start.py prod      # Start production server
python start.py check     # System health check

# Database management
python init_db.py init    # Initialize database tables
python init_db.py demo    # Create demo data
python init_db.py reset   # Reset database (âš ï¸ deletes all data)
```

### Frontend Commands
```bash
npm run dev               # Start development server
npm run build             # Build for production
npm run build:dev         # Build for development
npm run preview           # Preview production build
npm run lint              # Run ESLint checks
```

## ğŸ‘¥ User Roles & Permissions

### Admin
- Full system access and configuration
- User management and system monitoring
- Data export and reporting capabilities

### Doctor/Clinician  
- Patient management and assessment administration
- View patient results and progress tracking
- Generate clinical reports

### Researcher
- Access aggregated, anonymized data
- Export data for research purposes
- Statistical analysis and reporting

## ğŸ” Troubleshooting

### Common Issues

**Backend won't start**
- Verify Python 3.8+ is installed
- Check all ML model files are present
- Ensure spaCy English model is downloaded: `python -m spacy download en_core_web_sm`

**Frontend build errors**
- Clear node_modules: `rm -rf node_modules && npm install`
- Check Node.js version (18+ required)
- Verify all dependencies are installed

**Database connection issues**
- Check database file permissions
- Verify DATABASE_URL in .env file
- Run database initialization: `python init_db.py demo`

**ML model loading errors**
- Ensure model files are in backend directory
- Check file permissions and formats
- Verify scikit-learn version compatibility

n a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For support and questions:
- Create an issue in the repository
- Check the API documentation at http://localhost:8000/docs
- Review the troubleshooting section above

## ğŸ™ Acknowledgments

- Built using scientifically-validated neuropsychological assessment protocols
- Incorporates research-based population norms for cognitive evaluation
- Uses advanced machine learning techniques for linguistic analysis
- Designed with healthcare professionals and researchers in mind

---

**Note**: This application is designed for research and clinical assessment purposes. It should be used alongside comprehensive clinical evaluation and should not replace professional medical diagnosis.
